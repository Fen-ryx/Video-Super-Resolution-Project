{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf1cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8ea598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Data_Upload\n",
    "class dataUpload:\n",
    "    \n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        data = []\n",
    "        for f in tqdm(os.listdir(self.label)):\n",
    "            path = os.path.join(self.label, f)\n",
    "            img = cv.imread(path)\n",
    "            data.append(img)\n",
    "        data = np.array(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04fbd413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocess to create training and test sets\n",
    "def gausBlurImg(img):\n",
    "    img = cv.GaussianBlur(img, (5, 5), 0)\n",
    "    return img\n",
    "\n",
    "def downSample(img, scale_factor):\n",
    "    img_dim = img.shape\n",
    "    orig_height, orig_width = img_dim[0], img_dim[1]\n",
    "    new_height, new_width = int(orig_height / scale_factor), int(orig_width / scale_factor)\n",
    "    new_img = cv.resize(img, (new_width, new_height))\n",
    "    return new_img\n",
    "\n",
    "def changeChannels(img):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2YUV)\n",
    "    return img\n",
    "\n",
    "def preProcess(img, scale_factor, change_channel = False, gausBlurImg = gausBlurImg, downSample = downSample, changeChannels = changeChannels):\n",
    "    img = gausBlurImg(img)\n",
    "    img = downSample(img, scale_factor)\n",
    "    if change_channel:\n",
    "        img = changeChannels(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c82609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_test_images(img, patch_size):\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    \n",
    "    while height % patch_size != 0:\n",
    "        height -= 1\n",
    "    while width % patch_size != 0:\n",
    "        width -= 1\n",
    "    \n",
    "    img = cv.resize(img, (width, height))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2a458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def patchify\n",
    "def img_to_patches(img, patch_size, stride):\n",
    "    patches = patchify(img, (patch_size, patch_size, 3), stride)\n",
    "    original_shape = patches.shape\n",
    "    patches = np.reshape(patches, (-1, patch_size, patch_size, 3))\n",
    "    return patches, original_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f4b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unpatchify\n",
    "def patches_to_img(patches_to_merge, merged_image_size):\n",
    "    reconstructed_img = unpatchify(patches_to_merge, merged_image_size)\n",
    "    return reconstructed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2819d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_generator\n",
    "def data_generator(images_array, batch_size, scale_factor, patch_size, stride, shuffle = True, change_channel = False, test = False, preProcess = preProcess, convert_test_images = convert_test_images):\n",
    "    num_images = len(images_array)\n",
    "    indices = [*range(num_images)]\n",
    "    index = 0\n",
    "    image_patches_X = []\n",
    "    image_patches_Y = []\n",
    "    LR_img_patches = []\n",
    "    HR_img_patches = []\n",
    "    \n",
    "    if shuffle:\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    while True:\n",
    "        epoch_counter = 0\n",
    "        if index >= num_images:\n",
    "            index = 0\n",
    "            epoch_counter = 1\n",
    "            if shuffle:\n",
    "                random.shuffle(indices)\n",
    "        \n",
    "        HR_img = images_array[indices[index]]\n",
    "        index += 1\n",
    "        \n",
    "        if test:\n",
    "            HR_img = convert_test_images(HR_img, patch_size * scale_factor)\n",
    "            LR_img = preProcess(HR_img, scale_factor)\n",
    "            LR_img_shape = LR_img.shape\n",
    "            LR_img_patches, original_shape = img_to_patches(LR_img, patch_size, stride)\n",
    "            HR_shape = (original_shape[0], original_shape[1], original_shape[2], original_shape[3] * scale_factor, original_shape[4] * scale_factor, original_shape[5])\n",
    "        else:\n",
    "            LR_img = preProcess(HR_img, scale_factor)\n",
    "            LR_img_patches, _ = img_to_patches(LR_img, patch_size, stride)\n",
    "            HR_img_patches, _ = img_to_patches(HR_img, patch_size * scale_factor, stride * scale_factor)\n",
    "        \n",
    "        if test:\n",
    "            X = torch.tensor(np.array(LR_img_patches))\n",
    "            X = X / 255.0\n",
    "            if index >= num_images - 1:\n",
    "                yield X, HR_shape, LR_img_shape, 1\n",
    "            else:\n",
    "                yield X, HR_shape, LR_img_shape, 0\n",
    "            continue\n",
    "        \n",
    "        for i in range(len(LR_img_patches)):\n",
    "            image_patches_X.append(LR_img_patches[i])\n",
    "            image_patches_Y.append(HR_img_patches[i])\n",
    "            \n",
    "            if len(image_patches_X) == batch_size:\n",
    "                X = torch.Tensor(np.array(image_patches_X))\n",
    "                Y = torch.Tensor(np.array(image_patches_Y))\n",
    "                X = X / 255.0\n",
    "                Y = Y / 255.0\n",
    "                yield X, Y, epoch_counter\n",
    "                image_patches_X = []\n",
    "                image_patches_Y = []\n",
    "        \n",
    "        image_patches_X = []\n",
    "        image_patches_Y = []\n",
    "        LR_img_patches = []\n",
    "        HR_img_patches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6487753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ESPCN\n",
    "class ESPCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, r):\n",
    "        super(ESPCN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(32, 3 * r * r, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(r)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.conv1(x))\n",
    "        x = torch.tanh(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d2d2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelDefinition(scale_factor, learning_rate, model_class = ESPCN):\n",
    "    model = model_class(scale_factor)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[30, 80], gamma=0.1)\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b052ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def training_loop\n",
    "def trainingLoop(train_generator, scale_factor, num_epochs, patch_size, model):    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        num_patches = 0\n",
    "        while True:\n",
    "            num_patches += 32\n",
    "            X, Y, count = next(train_generator)\n",
    "            X = torch.reshape(X, (-1, 3, patch_size, patch_size))\n",
    "            Y = torch.reshape(Y, (-1, 3, patch_size * scale_factor, patch_size * scale_factor))\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = loss_fn(output, Y)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(f\"Loss after {num_patches} patches: {loss.item()}\")\n",
    "            \n",
    "            if count == 1:\n",
    "                break\n",
    "        \n",
    "        #print(f\"Loss After {epoch + 1} Epochs: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18885ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_loop\n",
    "def testLoop(test_generator, scale_factor, patch_size, model):\n",
    "    SR_images = []\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            X, original_shape, LR_img_shape, count = next(test_generator)\n",
    "            X = torch.reshape(X, (-1, 3, patch_size, patch_size))\n",
    "            output = model(X)\n",
    "            output = np.array(output)\n",
    "            output = np.reshape(output, original_shape)\n",
    "            SR_img = patches_to_img(output, (LR_img_shape[0] * scale_factor, LR_img_shape[1] * scale_factor, 3))\n",
    "            SR_images.append(SR_img)\n",
    "            if count == 1:\n",
    "                break\n",
    "    \n",
    "    SR_images = np.array(SR_images)\n",
    "    return SR_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "055a1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgSave(test_generator, scale_factor, patch_size, model, testLoop = testLoop):\n",
    "    SR_images = testLoop(test_generator, scale_factor, patch_size, model)\n",
    "    for i, img in enumerate(SR_images):\n",
    "        cv.imwrite(r\"C:\\Users\\Gaurav\\Datasets\\SoC_Assignment\\Test_Dataset\\Test_Results\\Image\" + str(i + 1) + \".jpg\", img * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f59ecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:00<00:00, 708.96it/s]\n",
      "C:\\Users\\Gaurav\\AppData\\Local\\Temp\\ipykernel_21860\\4266270226.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(data)\n",
      "100%|██████████| 10/10 [00:00<00:00, 291.33it/s]\n"
     ]
    }
   ],
   "source": [
    "train_label = r\"C:\\Users\\Gaurav\\Datasets\\SoC_Assignment\\T91\"\n",
    "test_label = r\"C:\\Users\\Gaurav\\Datasets\\SoC_Assignment\\Test_Dataset\"\n",
    "\n",
    "train_obj = dataUpload(train_label)\n",
    "test_obj = dataUpload(test_label)\n",
    "\n",
    "train_data = train_obj.create_dataset()\n",
    "test_data = test_obj.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab77f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "scale_factor = 2\n",
    "patch_size = 8\n",
    "stride = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96c61725",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_fn, optimizer = modelDefinition(scale_factor, learning_rate, model_class = ESPCN)\n",
    "train_generator = data_generator(train_data, batch_size, scale_factor, patch_size, stride)\n",
    "test_generator = data_generator(test_data, batch_size, scale_factor, patch_size, stride, shuffle = False, change_channel = False, test = True, preProcess = preProcess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8b0fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingLoop(train_generator, scale_factor, num_epochs, patch_size, model)\n",
    "torch.save(model.state_dict(), r\"C:\\Users\\Gaurav\\Seasons_of_Code_Project_Work\\Model_Weights\\ESPCN_Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07f37c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaurav\\AppData\\Local\\Temp\\ipykernel_21860\\2767749179.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  SR_images = np.array(SR_images)\n"
     ]
    }
   ],
   "source": [
    "imgSave(test_generator, scale_factor, patch_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e59ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(SR_img, HR_img):\n",
    "    HR_img = cv.resize(HR_img, (SR_img.shape[1], SR_img.shape[0]))\n",
    "    SR_img = cv.cvtColor(SR_img, cv.COLOR_BGR2YUV)\n",
    "    HR_img = cv.cvtColor(HR_img, cv.COLOR_BGR2YUV)\n",
    "    SR_img, _, _ = cv.split(SR_img)\n",
    "    HR_img, _, _ = cv.split(HR_img)\n",
    "    \n",
    "    peak_value = np.max(HR_img)\n",
    "    mse = np.sum(np.sum(np.square(HR_img - SR_img), axis = 0)) / (HR_img.shape[0] * HR_img.shape[1])\n",
    "    \n",
    "    psnr = np.log10(peak_value / np.sqrt(mse))\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c4226f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 177.52it/s]\n",
      "C:\\Users\\Gaurav\\AppData\\Local\\Temp\\ipykernel_21860\\4266270226.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(data)\n",
      "100%|██████████| 91/91 [00:00<00:00, 583.08it/s]\n"
     ]
    }
   ],
   "source": [
    "SR_Images_Obj = dataUpload(r\"C:\\Users\\Gaurav\\Datasets\\SoC_Assignment\\Test_Results\")\n",
    "HR_Images_Obj = dataUpload(r\"C:\\Users\\Gaurav\\Datasets\\SoC_Assignment\\T91\")\n",
    "\n",
    "SR_Images = SR_Images_Obj.create_dataset()\n",
    "HR_Images = HR_Images_Obj.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63cfbee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr_calculator(SR_Images, HR_Images, PSNR = PSNR):\n",
    "    psnr_total = 0\n",
    "    \n",
    "    for SR_img, HR_img in zip(SR_Images, HR_Images):\n",
    "        psnr_total += PSNR(SR_img, HR_img)\n",
    "    \n",
    "    return psnr_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3d5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataUploadVideo:\n",
    "    \n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        data = []\n",
    "        for f in tqdm(os.listdir(self.label)):\n",
    "            cur_video_frames = []\n",
    "            path = os.path.join(self.label, f)\n",
    "            \n",
    "            if \".yuv\" in path:\n",
    "                capture = cv.VideoCapture(path)\n",
    "\n",
    "                while True:\n",
    "                    isTrue, frame = capture.read()\n",
    "                    if not isTrue:\n",
    "                        break\n",
    "                    cur_video_frames.append(frame)\n",
    "\n",
    "                data.append(np.array(cur_video_frames))\n",
    "        \n",
    "        return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85318686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 19.90it/s]\n"
     ]
    }
   ],
   "source": [
    "label = r\"C:\\Users\\Gaurav\\Datasets\\SoC_Final_Video\"\n",
    "\n",
    "video_obj = dataUploadVideo(label)\n",
    "\n",
    "video_dataset = video_obj.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "259fe77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(video_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2af8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset_BGR = []\n",
    "video_dataset_LR = []\n",
    "\n",
    "for video in video_dataset:\n",
    "    video_BGR = []\n",
    "    video_LR = []\n",
    "    for frame in video:\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_YUV2BGR)\n",
    "        LR_frame = gausBlurImg(frame)\n",
    "        LR_frame = downSample(LR_frame, scale_factor)\n",
    "        video_BGR.append(frame)\n",
    "        video_LR.append(LR_frame)\n",
    "    video_dataset_BGR.append(video)\n",
    "\n",
    "video_dataset_BGR = np.array(video_dataset_BGR)\n",
    "video_dataset_LR = np.array(video_dataset_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b92d406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_be_passed = []\n",
    "\n",
    "for video in video_dataset_LR:\n",
    "    video_to_be_passed = []\n",
    "    for frame in video:\n",
    "        frame_patches, original_patch_shape = img_to_patches(frame, patch_size, stride)\n",
    "        video_to_be_passed.append(frame_patches)\n",
    "    dataset_to_be_passed.append(video_to_be_passed)\n",
    "\n",
    "data_set_to_be_passed = np.array(dataset_to_be_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3358a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for video in dataset_to_be_passed:\n",
    "        for frame in video:\n",
    "            for patch in frame:\n",
    "                patch = torch.Tensor(patch)\n",
    "                patch = torch.reshape(patch, (-1, 3, patch_size, patch_size))\n",
    "                output = model(patch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
